# AI-Legal: Legal Document Analysis & Violation Prediction

An AI-powered system for analyzing legal documents and predicting ECHR violations using LegalBERT with web interface.

## ğŸ¯ Overview

- **ğŸ“„ PDF & Text Processing**: Extract and analyze legal documents
- **ğŸ” Violation Prediction**: LegalBERT-based ECHR violation detection
- **ğŸ“ Intelligent Summarization**: T5-based case summarization
- **ğŸ”— Similar Case Retrieval**: Find relevant precedents via Google Search
- **ğŸŒ Web Interface**: Flask web application

## ğŸš€ Quick Start

### Installation

```bash

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt
```

### Run Application

```bash
python app.py
# Visit http://localhost:8000
```

## ğŸ“Š Model Info

- **Architecture**: LegalBERT (nlpaueb/legal-bert-base-uncased)
- **Test Accuracy**: ~91%
- **F1 Score**: ~0.91
- **Training Data**: 10,000 balanced ECHR cases
- **Max Sequence Length**: 512 tokens

## ğŸ“ Structure

```
AI-Legal/
â”œâ”€â”€ app.py                          # Flask application
â”œâ”€â”€ notebook9ff22b1d39.ipynb        # Training notebook
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ legalbert_echr_model/       # Trained model
â”‚   â”œâ”€â”€ legalbert_echr_model_best/  # Best checkpoint
â”‚   â””â”€â”€ legalbert_echr_model_last/  # Last checkpoint
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                  # Web UI
â”œâ”€â”€ static/
â”‚   â””â”€â”€ styles.css                  # Styling
â””â”€â”€ New folder/all-data/            # Training dataset
```

## ğŸ”§ Configuration

Edit `app.py` to set:
```python
GOOGLE_API_KEY = "your-api-key"
CSE_ID = "your-cse-id"
MODEL_PATH = "models/legalbert_echr_model"
```

## ğŸ“š API Endpoints

### POST `/analyze`
Analyze text or PDF document
```json
{
  "text": "Case facts...",
  "pdf": "<file>"
}
```

### POST `/analyze_url`
Analyze content from URL
```json
{
  "url": "https://example.com"
}
```

## ğŸ“ˆ Performance

| Metric | Score |
|--------|-------|
| Accuracy | 91.2% |
| Precision | 0.890 |
| Recall | 0.923 |
| F1 Score | 0.906 |

## ğŸ› ï¸ Tech Stack

- **Backend**: Flask, PyTorch, Transformers
- **NLP Models**: LegalBERT, T5
- **Data**: Pandas, NumPy, scikit-learn
- **PDF**: PyMuPDF
- **Frontend**: HTML5, CSS3, JavaScript

## ğŸ“ Training Pipeline

1. Data loading from ECHR JSON dataset
2. Text extraction (facts, arguments, law sections)
3. Data cleaning & leakage removal
4. Dataset balancing (5K violation + 5K no-violation)
5. Tokenization with LegalBERT
6. Training (2 epochs, lr=2e-5)
7. Fine-tuning (2 epochs, lr=1e-5)

## âš™ï¸ Key Hyperparameters

- Batch Size: 4
- Learning Rate: 2e-5 â†’ 1e-5
- Max Length: 512 tokens
- Optimizer: AdamW
- Warmup: 10% of total steps

## ğŸš¨ Limitations

- ECHR-specific training
- Max document length: 512 tokens
- Requires fine-tuning for other jurisdictions
- Google Search API rate limits

## ğŸ“– Notebook Sections

The training notebook includes:
1. Data Loading & Exploration
2. Label Extraction & Distribution
3. Text Field Extraction
4. Data Cleaning & Deduplication
5. Leakage Phrase Removal
6. Dataset Balancing
7. Text Normalization
8. Train/Val/Test Split (80/10/10)
9. Tokenization
10. PyTorch Dataset & DataLoader
11. Model Loading & Training
12. Evaluation & Metrics
13. Model Saving
14. Inference Functions
15. Fine-tuning
16. Model Reloading


## ğŸ“„ License

Educational and research purposes.

---

**Last Updated**: November 2025  
**Status**: Active
